{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8324264-9061-40de-ac8d-d2147047a478",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing recommended libraries\n",
    "import cv2  \n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "from tensorflow.keras.applications import ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d9a14ef-e5c9-444c-a814-14aa4779cc28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main directory where model data is saved\n",
    "mainDataDirectory = \"C:/Users/seyed/Music/Brain Tumor - Model Data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c4813c2-e137-4ae4-96a4-74a7bed95a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categories of image classification\n",
    "imageCategories = [\"No\", \"Yes\"]\n",
    "\n",
    "# Directories for training and testing data\n",
    "trainDirectory = os.path.join(mainDataDirectory, 'Train')\n",
    "testDirectory = os.path.join(mainDataDirectory, 'Test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a642e5f0-faca-42fb-8d68-fd023c040b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to read images from a directory and add labels to each image\n",
    "def read_images_from_directory(directory):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for imageCategory in imageCategories:\n",
    "        category_path = os.path.join(directory, imageCategory)\n",
    "        label = imageCategories.index(imageCategory)\n",
    "        \n",
    "        for filename in os.listdir(category_path):\n",
    "            image_path = os.path.join(category_path, filename)\n",
    "            image = cv2.imread(image_path)\n",
    "            if image is not None:\n",
    "                images.append(image)\n",
    "                labels.append(label)\n",
    "            else:\n",
    "                print(f\"Error in reading the image: {image_path}\")\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5fa52528-d648-4a38-817d-3fc41e93d232",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read training images\n",
    "train_images, train_labels = read_images_from_directory(trainDirectory)\n",
    "\n",
    "# Read testing images\n",
    "test_images, test_labels = read_images_from_directory(testDirectory)\n",
    "\n",
    "# Convert the lists to numpy arrays\n",
    "train_images = np.array(train_images)\n",
    "train_labels = np.array(train_labels)\n",
    "test_images = np.array(test_images)\n",
    "test_labels = np.array(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a9e0273-964e-47af-b6cb-73cdd11b45fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding the label\n",
    "label_encoder = LabelEncoder()\n",
    "train_label_encoded = label_encoder.fit_transform(train_labels)\n",
    "test_label_encoded = label_encoder.fit_transform(test_labels)\n",
    "\n",
    "# Convert the encoded labels to one-hot encoding\n",
    "train_labels_onehot = to_categorical(train_label_encoded, num_classes=2)\n",
    "test_labels_onehot = to_categorical(test_label_encoded, num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b52b65a5-607a-4b0d-b1dc-05102d02016a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "94765736/94765736 [==============================] - 15s 0us/step\n",
      "Epoch 1/10\n",
      "2595/2595 [==============================] - 1553s 597ms/step - loss: 0.5464 - accuracy: 0.9417 - val_loss: 0.0445 - val_accuracy: 0.9832\n",
      "Epoch 2/10\n",
      "2595/2595 [==============================] - 1547s 596ms/step - loss: 0.1280 - accuracy: 0.9549 - val_loss: 0.0675 - val_accuracy: 0.9796\n",
      "Epoch 3/10\n",
      "2595/2595 [==============================] - 1546s 596ms/step - loss: 0.1203 - accuracy: 0.9537 - val_loss: 0.0566 - val_accuracy: 0.9765\n",
      "Epoch 4/10\n",
      "2595/2595 [==============================] - 1546s 596ms/step - loss: 0.1125 - accuracy: 0.9612 - val_loss: 0.0643 - val_accuracy: 0.9855\n",
      "Epoch 5/10\n",
      "2595/2595 [==============================] - 1545s 595ms/step - loss: 0.0874 - accuracy: 0.9710 - val_loss: 0.0235 - val_accuracy: 0.9907\n",
      "Epoch 6/10\n",
      "2595/2595 [==============================] - 1544s 595ms/step - loss: 0.0785 - accuracy: 0.9755 - val_loss: 0.0290 - val_accuracy: 0.9903\n",
      "Epoch 7/10\n",
      "2595/2595 [==============================] - 1542s 594ms/step - loss: 0.0821 - accuracy: 0.9732 - val_loss: 0.0364 - val_accuracy: 0.9945\n",
      "Epoch 8/10\n",
      "2595/2595 [==============================] - 1545s 595ms/step - loss: 0.0800 - accuracy: 0.9721 - val_loss: 0.0383 - val_accuracy: 0.9934\n",
      "Epoch 9/10\n",
      "2595/2595 [==============================] - 1544s 595ms/step - loss: 0.0721 - accuracy: 0.9769 - val_loss: 0.0256 - val_accuracy: 0.9934\n",
      "Epoch 10/10\n",
      "2595/2595 [==============================] - 1545s 595ms/step - loss: 0.0738 - accuracy: 0.9757 - val_loss: 0.0228 - val_accuracy: 0.9924\n"
     ]
    }
   ],
   "source": [
    "# Running the tf in cpu\n",
    "with tf.device('/cpu:0'):\n",
    "    # Loading the vgg16 model and setting up the image size to train\n",
    "    base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(256, 256, 3))\n",
    "\n",
    "    # Freeze the layers\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "    \n",
    "    # Update the model architecture\n",
    "    model = models.Sequential()\n",
    "    model.add(base_model)\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(256, activation='relu'))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Dense(2, activation='softmax'))  \n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    # Train the model\n",
    "    history = model.fit(train_images, train_labels_onehot, epochs=10, batch_size=16, validation_data=(test_images, test_labels_onehot))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5345ea9c-dc7e-4cbd-b9a7-12959d4076cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model.save('C:/Users/seyed/Music/Brain Tumor - Model/TumorDetectionModel_ResNet50.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cdd447a8-6dd1-4663-b95f-5b853c4c903c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " resnet50 (Functional)       (None, 8, 8, 2048)        23587712  \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 131072)            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               33554688  \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2)                 514       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 57,142,914\n",
      "Trainable params: 33,555,202\n",
      "Non-trainable params: 23,587,712\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Displayed the trained model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5637bd-3f5e-41fd-912c-a9f617f0a752",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
